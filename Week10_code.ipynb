{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. suffix trie\n",
    "def TrieConstruction(Patterns: List[str]) -> List[Tuple[int, int, str]]:\n",
    "    node_counter = 0  \n",
    "    trie = []  \n",
    "    \n",
    "    children = {node_counter: {}}\n",
    "    \n",
    "    for pattern in Patterns:\n",
    "        currentNode = 0 \n",
    "        for symbol in pattern:\n",
    "            if symbol in children[currentNode]:  \n",
    "                currentNode = children[currentNode][symbol]\n",
    "            else:\n",
    "                node_counter += 1  # Create a new node\n",
    "                trie.append((currentNode, node_counter, symbol))  \n",
    "                children[currentNode][symbol] = node_counter  \n",
    "                currentNode = node_counter \n",
    "                children[currentNode] = {}\n",
    "                \n",
    "    return trie \n",
    "\n",
    "# 2. suffix tree\n",
    "def DFS(start, graph, visited = set(), path = [], all_paths = []):\n",
    "        visited.add(start)\n",
    "        path = path + [start]\n",
    "        \n",
    "        # If current node is a leaf or a branching node, return the path\n",
    "        if start not in graph or len(list(graph[start].values())) != 1:\n",
    "            all_paths.append(path)\n",
    "        else:\n",
    "            for neighbor in list(graph[start].values()):\n",
    "                if neighbor not in visited:  \n",
    "                    DFS(neighbor,graph, visited, path, all_paths)\n",
    "\n",
    "# Please do not remove package declarations because these are used by the autograder.\n",
    "def suffix_tree(text: str) -> List[str]:\n",
    "    # build the suffix trie first\n",
    "    node_counter = 0  \n",
    "    edge = {}\n",
    "    children = {node_counter: {}}\n",
    "    \n",
    "    for i in range(len(text)):\n",
    "        currentNode = 0 \n",
    "        for j in range(i, len(text)):\n",
    "            symbol = text[j]\n",
    "            if symbol in children[currentNode]:  \n",
    "                currentNode = children[currentNode][symbol]\n",
    "            else:\n",
    "                node_counter += 1\n",
    "                edge[(currentNode, node_counter)] = symbol\n",
    "                children[currentNode][symbol] = node_counter  \n",
    "                currentNode = node_counter \n",
    "                children[currentNode] = {}\n",
    "\n",
    "    # use DFS to traverse the tree and finding all non-branching path\n",
    "    non_branching_paths = []\n",
    "    visited = set()\n",
    "    for start_node in children.keys():\n",
    "        if start_node != 0 and start_node not in visited:\n",
    "            DFS(start_node, children, visited, [], non_branching_paths)\n",
    "    # now paths include list with len = 1, these are leaves or branching node.\n",
    "    # for them find there parent and keep those edge\n",
    "    # for lists with len > 1, they are those need condensed and replaced by a new node.\n",
    "    tree = {}\n",
    "    for p in non_branching_paths:\n",
    "        label = \"\"\n",
    "        for e in edge.keys():\n",
    "            if e[1] == p[0]:\n",
    "                parent = e[0]\n",
    "                label = edge[e]\n",
    "                if len(p) == 1:\n",
    "                    tree[(parent,e[1])] = label\n",
    "                elif len(p) > 1:\n",
    "                    suffix = \"\"\n",
    "                    for i in range(len(p)-1):\n",
    "                        currentEdge = (p[i],p[i+1])\n",
    "                        suffix += edge[currentEdge]\n",
    "                    label += suffix\n",
    "                    node_counter += 1\n",
    "                    tree[(parent, node_counter)] = label\n",
    "    #print(tree)\n",
    "    return list(tree.values())\n",
    "\n",
    "\n",
    "# 3. longest_repeat\n",
    "def suffix_array(text: str) -> List[int]:\n",
    "    \"\"\"\n",
    "    Generate the suffix array for the given text.\n",
    "    \"\"\"\n",
    "    size = len(text)\n",
    "    suffix = [[text[i:], i] for i in range(size)]\n",
    "    # Sort the suffixes lexicographically\n",
    "    sorted_suffixes = sorted(suffix)\n",
    "    \n",
    "    # Extract and return the indices of the sorted suffixes\n",
    "    suffix_array = [idx for (suff, idx) in sorted_suffixes]\n",
    "    return suffix_array\n",
    "\n",
    "\n",
    "def build_lcp_array(s, suffix_array):\n",
    "        n = len(s)\n",
    "        lcp = [0] * (n - 1)  # Adjusted for the correct size\n",
    "        rank = [0] * n\n",
    "        for i, suffix in enumerate(suffix_array):\n",
    "            rank[suffix] = i\n",
    "        k = 0\n",
    "        for i in range(n):\n",
    "            if rank[i] == n - 1:\n",
    "                k = 0  \n",
    "                continue\n",
    "            # Next suffix in the sorted order\n",
    "            j = suffix_array[rank[i] + 1]\n",
    "            # Increase `k` as long as the next character is the same for both suffixes\n",
    "            while i + k < n and j + k < n and s[i + k] == s[j + k]:\n",
    "                k += 1\n",
    "            lcp[rank[i]] = k\n",
    "            if k > 0: k -= 1  # Decrease `k` for the next iteration\n",
    "        \n",
    "        return lcp\n",
    "# Insert your longest_repeat function here, along with any subroutines you need\n",
    "def longest_repeat(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Find the longest repeated substring in the given text.\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "            return \"\"  # Handle empty string case\n",
    "    array = suffix_array(text)\n",
    "    lcp_array = build_lcp_array(text, array)\n",
    "    max_length, index = max((lcp, idx) for idx, lcp in enumerate(lcp_array))\n",
    "    \n",
    "    # Return the longest repeated substring found\n",
    "    return text[array[index]:array[index] + max_length] if max_length > 0 else \"\"\n",
    "\n",
    "\n",
    "# 4. longest substring\n",
    "# Please do not remove package declarations because these are used by the autograder.\n",
    "def suffix_array(text) -> List[int]:\n",
    "    \"\"\"\n",
    "    Generate the suffix array for the given text.\n",
    "    \"\"\"\n",
    "    size = len(text)\n",
    "    suffix = [[text[i:], i] for i in range(size)]\n",
    "    # Sort the suffixes lexicographically\n",
    "    sorted_suffixes = sorted(suffix)\n",
    "    \n",
    "    # Extract and return the indices of the sorted suffixes\n",
    "    # idx is the position of the suffix start in text\n",
    "    suffix_array = [idx for (suff, idx) in sorted_suffixes]\n",
    "    return suffix_array\n",
    "\n",
    "# stores the lengths of the longest common prefixes between all pairs of consecutive suffixes in the sorted suffix array of a string. \n",
    "def build_lcp_array(text, suffix_array, delimiter):\n",
    "        n = len(text)\n",
    "        lcp = [0] * (n - 1)  # in this case we only compare and find LCPs of the first n suffices\n",
    "        rank = [0] * n\n",
    "        for i, suffix in enumerate(suffix_array):\n",
    "            # the rank of each suffix in the suffix array\n",
    "            rank[suffix] = i\n",
    "        k = 0\n",
    "        for i in range(n):\n",
    "            # if its the last suffix, there is no one it can compare to so skip\n",
    "            if rank[i] == n - 1:\n",
    "                k = 0  \n",
    "                continue\n",
    "            # Next suffix in the sorted order\n",
    "            j = suffix_array[rank[i] + 1]\n",
    "            if (i-delimiter)*(j-delimiter) < 0:\n",
    "                # Increase `k` as long as the next character is the same for both suffixes\n",
    "                while i + k < n and j + k < n and text[i + k] == text[j + k]:\n",
    "                    k += 1\n",
    "                lcp[rank[i]] = k\n",
    "                if k > 0: k -= 1  # Decrease `k` for the next iteration\n",
    "        \n",
    "        return lcp\n",
    "\n",
    "# Insert your longest_shared_substring function here, along with any subroutines you need\n",
    "def longest_shared_substring(text1: str, text2: str) -> str:\n",
    "    \"\"\"\n",
    "    Find the longest shared substring between two texts. Find the longest substring repeat of the concatenated text, which is the deepest internal node has two branches one branch to $ one branch to #.\n",
    "    \"\"\"\n",
    "    # ended two string with two different stop sign, text1 with $, text2 with #.\n",
    "    text = text1 + \"$\" + text2\n",
    "    array = suffix_array(text)\n",
    "    # the position of delimiter\n",
    "    delimiter = len(text1)\n",
    "    lcp_array = build_lcp_array(text, array, delimiter)\n",
    "    max_length, index = max((lcp, idx) for idx, lcp in enumerate(lcp_array))\n",
    "    # Return the longest repeated substring found\n",
    "    return text[array[index]:array[index] + max_length] if max_length > 0 else \"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 5. suffix array\n",
    "def suffix_array(text: str) -> List[int]:\n",
    "    \"\"\"\n",
    "    Generate the suffix array for the given text.\n",
    "    \"\"\"\n",
    "    size = len(text)\n",
    "    suffix = [[text[i:], i] for i in range(size)]\n",
    "    # Sort the suffixes lexicographically\n",
    "    sorted_suffixes = sorted(suffix)\n",
    "    \n",
    "    # Extract and return the indices of the sorted suffixes\n",
    "    suffix_array = [idx for (suff, idx) in sorted_suffixes]\n",
    "    return suffix_array"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
